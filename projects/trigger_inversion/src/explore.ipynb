{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eecs/jialin_song/anaconda3/envs/round11_explore/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import cv2\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_FILEDIR = '/scratch/data/TrojAI/image-classification-sep2022-train/models/'\n",
    "METADATA_FILEPATH = '/scratch/data/TrojAI/image-classification-sep2022-train/METADATA.csv'\n",
    "MODEL_ARCH = ['classification:' + arch for arch in ['resnet50', 'vit_base_patch32_224', 'mobilenet_v2']]\n",
    "NUM_MODEL = 288\n",
    "OUTPUT_FILEDIR = '/scratch/jialin/image-classification-sep2022/projects/weight_analysis/extracted_source/'\n",
    "EXAMPLE_SRC_DIR = '/scratch/data/TrojAI/image-classification-sep2022-train/image-classification-sep2022-example-source-dataset'\n",
    "\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "\n",
    "def num_to_model_id(num):\n",
    "    return 'id-' + str(100000000+num)[1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>converged</th>\n",
       "      <th>nonconverged_reason</th>\n",
       "      <th>master_seed</th>\n",
       "      <th>task_type_level</th>\n",
       "      <th>task_type</th>\n",
       "      <th>source_dataset_level</th>\n",
       "      <th>source_dataset</th>\n",
       "      <th>model_architecture</th>\n",
       "      <th>model_architecture_level</th>\n",
       "      <th>...</th>\n",
       "      <th>trigger_2.trigger_size_restriction_option</th>\n",
       "      <th>trigger_2.polygon_texture_augmentation_level</th>\n",
       "      <th>trigger_2.polygon_texture_augmentation</th>\n",
       "      <th>trigger_2.size_percentage_of_foreground_min</th>\n",
       "      <th>trigger_2.size_percentage_of_foreground_max</th>\n",
       "      <th>trigger_2.min_area</th>\n",
       "      <th>trigger_2.spatial_quadrant_level</th>\n",
       "      <th>trigger_2.spatial_quadrant</th>\n",
       "      <th>trigger_2.options_level</th>\n",
       "      <th>trigger_2.options</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id-00000000</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>354103127</td>\n",
       "      <td>0</td>\n",
       "      <td>classification</td>\n",
       "      <td>0</td>\n",
       "      <td>cityscapes</td>\n",
       "      <td>classification:resnet50</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id-00000001</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2049821827</td>\n",
       "      <td>0</td>\n",
       "      <td>classification</td>\n",
       "      <td>0</td>\n",
       "      <td>cityscapes</td>\n",
       "      <td>classification:vit_base_patch32_224</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id-00000002</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>74361305</td>\n",
       "      <td>0</td>\n",
       "      <td>classification</td>\n",
       "      <td>0</td>\n",
       "      <td>cityscapes</td>\n",
       "      <td>classification:mobilenet_v2</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id-00000003</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>197593124</td>\n",
       "      <td>0</td>\n",
       "      <td>classification</td>\n",
       "      <td>0</td>\n",
       "      <td>cityscapes</td>\n",
       "      <td>classification:resnet50</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id-00000004</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>69550395</td>\n",
       "      <td>0</td>\n",
       "      <td>classification</td>\n",
       "      <td>0</td>\n",
       "      <td>cityscapes</td>\n",
       "      <td>classification:resnet50</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 216 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    model_name  converged  nonconverged_reason  master_seed  task_type_level  \\\n",
       "0  id-00000000       True                  NaN    354103127                0   \n",
       "1  id-00000001       True                  NaN   2049821827                0   \n",
       "2  id-00000002       True                  NaN     74361305                0   \n",
       "3  id-00000003       True                  NaN    197593124                0   \n",
       "4  id-00000004       True                  NaN     69550395                0   \n",
       "\n",
       "        task_type  source_dataset_level source_dataset  \\\n",
       "0  classification                     0     cityscapes   \n",
       "1  classification                     0     cityscapes   \n",
       "2  classification                     0     cityscapes   \n",
       "3  classification                     0     cityscapes   \n",
       "4  classification                     0     cityscapes   \n",
       "\n",
       "                    model_architecture  model_architecture_level  ...  \\\n",
       "0              classification:resnet50                         3  ...   \n",
       "1  classification:vit_base_patch32_224                         6  ...   \n",
       "2          classification:mobilenet_v2                         5  ...   \n",
       "3              classification:resnet50                         3  ...   \n",
       "4              classification:resnet50                         3  ...   \n",
       "\n",
       "  trigger_2.trigger_size_restriction_option  \\\n",
       "0                                       NaN   \n",
       "1                                       NaN   \n",
       "2                                       NaN   \n",
       "3                                       NaN   \n",
       "4                                       NaN   \n",
       "\n",
       "   trigger_2.polygon_texture_augmentation_level  \\\n",
       "0                                           NaN   \n",
       "1                                           NaN   \n",
       "2                                           NaN   \n",
       "3                                           NaN   \n",
       "4                                           NaN   \n",
       "\n",
       "  trigger_2.polygon_texture_augmentation  \\\n",
       "0                                    NaN   \n",
       "1                                    NaN   \n",
       "2                                    NaN   \n",
       "3                                    NaN   \n",
       "4                                    NaN   \n",
       "\n",
       "   trigger_2.size_percentage_of_foreground_min  \\\n",
       "0                                          NaN   \n",
       "1                                          NaN   \n",
       "2                                          NaN   \n",
       "3                                          NaN   \n",
       "4                                          NaN   \n",
       "\n",
       "   trigger_2.size_percentage_of_foreground_max  trigger_2.min_area  \\\n",
       "0                                          NaN                 NaN   \n",
       "1                                          NaN                 NaN   \n",
       "2                                          NaN                 NaN   \n",
       "3                                          NaN                 NaN   \n",
       "4                                          NaN                 NaN   \n",
       "\n",
       "   trigger_2.spatial_quadrant_level  trigger_2.spatial_quadrant  \\\n",
       "0                               NaN                         NaN   \n",
       "1                               NaN                         NaN   \n",
       "2                               NaN                         NaN   \n",
       "3                               NaN                         NaN   \n",
       "4                               NaN                         NaN   \n",
       "\n",
       "   trigger_2.options_level  trigger_2.options  \n",
       "0                      NaN                NaN  \n",
       "1                      NaN                NaN  \n",
       "2                      NaN                NaN  \n",
       "3                      NaN                NaN  \n",
       "4                      NaN                NaN  \n",
       "\n",
       "[5 rows x 216 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "METADATA = pd.read_csv(METADATA_FILEPATH)\n",
    "METADATA.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = os.path.join(MODEL_FILEDIR, num_to_model_id(0))\n",
    "model_filepath = os.path.join(model_dir, 'model.pt')\n",
    "clean_images_dir = os.path.join(model_dir, 'clean-example-data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_output_from_example_images(model_filepath, image_filedir, device, loss_fn):\n",
    "    image_filepaths = [os.path.join(image_filedir, img) for img in os.listdir(image_filedir) if img.endswith('.jpg')]\n",
    "    image_filepaths.sort()\n",
    "\n",
    "    images, targets, ids = [], [], []\n",
    "    for image_filepath in image_filepaths:\n",
    "        image_id = os.path.basename(image_filepath)\n",
    "        image_id = int(image_id.replace('.jpg',''))\n",
    "        img = cv2.imread(image_filepath, cv2.IMREAD_UNCHANGED)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        with open(image_filepath.replace('.jpg', '.json')) as json_file:\n",
    "            target = json.load(json_file)\n",
    "\n",
    "        # with torch.no_grad():\n",
    "        img = torch.as_tensor(img).permute((2, 0, 1))\n",
    "        img = torchvision.transforms.functional.convert_image_dtype(img, torch.float)\n",
    "\n",
    "        images.append(img)\n",
    "        targets.append(target)\n",
    "        ids.append(image_id)\n",
    "    \n",
    "    # with torch.no_grad():\n",
    "    images = [image.to(device) for image in images]\n",
    "    images = [image.requires_grad_() for image in images]\n",
    "    images = torch.stack(images, 0)\n",
    "    images.retain_grad()\n",
    "    \n",
    "    model = torch.load(model_filepath).to(device)\n",
    "    model.eval()\n",
    "\n",
    "    logits = model(images)\n",
    "    \n",
    "    loss = loss_fn(logits, torch.as_tensor(targets, dtype=torch.long, device=device))\n",
    "    loss.backward()\n",
    "\n",
    "    del model\n",
    "\n",
    "    return {'image_id': ids, 'logits':logits.cpu(), 'targets': targets, 'grad_images': images.grad.cpu()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dict = get_output_from_example_images(model_filepath, clean_images_dir, DEVICE, torch.nn.CrossEntropyLoss())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20, 119])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_dict['logits'].shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('round11_explore')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7b3d3baff363ffdd8f715871afbbb0158a35eb16105cf8b9c52841935e588fec"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
